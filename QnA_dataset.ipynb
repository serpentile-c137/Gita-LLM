{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703487bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing processed_data/gita_qa_dataset_per_verse_01.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_02.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_03.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_04.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_05.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_06.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_07.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_08.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_09.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_10.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_11.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_12.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_13.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_14.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_15.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_16.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_17.jsonl\n",
      "Processing processed_data/gita_qa_dataset_per_verse_18.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "input_dir = \"processed_data\"  # replace with your directory path\n",
    "output_file = \"gita_qa_final.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for filename in sorted(os.listdir(input_dir)):\n",
    "        if filename.endswith(\".jsonl\"):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            print(f\"Processing {file_path}\")\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aaffa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1265 examples [00:00, 244777.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating repo: serpentilec137/gita-verse-qna-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 387.00ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset pushed to: https://huggingface.co/datasets/serpentilec137/gita-verse-qna-dataset\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi\n",
    "from pathlib import Path\n",
    "\n",
    "# Config\n",
    "dataset_path = \"gita_qa_final.jsonl\"\n",
    "repo_name = \"gita-verse-qna-dataset\"  # Customize this\n",
    "hf_api = HfApi()\n",
    "username = hf_api.whoami()[\"name\"]\n",
    "repo_id = f\"{username}/{repo_name}\"\n",
    "\n",
    "# Step 1: Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"json\", data_files=dataset_path, split=\"train\")\n",
    "\n",
    "# Step 2: Push to Hub\n",
    "print(f\"Creating repo: {repo_id}\")\n",
    "dataset.push_to_hub(repo_id)\n",
    "print(f\"✅ Dataset pushed to: https://huggingface.co/datasets/{repo_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17d380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1265/1265 [00:00<00:00, 167973.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'In Bhagavad Gita 1.1, what question did Dhrtarastra ask Sanjaya about the assembly at Kuruksetra?', 'answer': \"Dhrtarastra asked: 'O Sanjaya, after assembling in the place of pilgrimage at Kuruksetra, what did my sons (mamakah) and the sons of Pandu (pandavas caiva) do, being desirous to fight (yuyutsavah)?'\", 'source_chapter': '1', 'source_verse': '1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"serpentilec137/gita-verse-qna-dataset\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb26036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
